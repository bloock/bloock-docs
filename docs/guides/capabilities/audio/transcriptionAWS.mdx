---
title: 'Transcriptions - AWS Transcribe'
sidebar_position: 2
sidebar_slug: transcriptions-aws
---

To add the realtime audio transcriptions in a Dyte meeting you can use AWS Transcribe & AWS Translate services

These AWS services are paid, an AWS account is required to proceed.

:::note

This integration is Web only at the moment

:::

# Integration Steps

## 1. Setup AWS IAM account, get credentials

To use AWS services, you should either be an IAM user, or your backend services should be deployed using roles & policies.

For ease of use, we are going ahead with IAM user credentials. Please ensure that the IAM user can actually use AWS transcribe & AWS translate services.

To proceed further, we need

- `accessKeyId`
- `secretAccessKey`

## 2. Setup a Server

Setup a server to forward the Audio Data from client to AWS Transcribe. You don't want to put your IAM credentials on client side and therefore need a server which forwards audio data to AWS

For this, we have provided the sample in NodeJS for you to checkout [dyte-io/aws-transcribe](https://github.com/dyte-io/aws-transcribe/tree/main/server). Currently, we only have an ExpressJS sample, if you working on a different backend, feel free to port this code or connect with us so that we can help you out in porting it.

To use this sample, Please clone this using the following command.

```
git clone git@github.com:dyte-io/aws-transcribe.git
```

### 2.1 Add your keys

```
cp .env.example .env
```

Edit it as per your AWS service account credentials and Save it.

### 2.2 Run the server

```
npm install
npm run dev
```

The HTTP endpoint where this server is accessible will now be called `backend_url` for remaining section of the guide

## Frontend Setup

### 3.1 Installation

```
npm install @dytesdk/aws-transcribe
```

Source available at (dyte-io/aws-transcribe)(https://github.com/dyte-io/aws-transcribe/tree/main/client)

### 3.2 Integrate

The second step is to look for the place in your codebase where you are initiating a Dyte meeting.

Once you have found the place and got a hold of the meeting object. Add the following code on top of the file to import the FE SDK.

```
import DyteAWSTranscribe from '@dytesdk/aws-transcribe';
```

Add the following code just after the point where you have access to the meeting object.

```ts
const awsTranscribe = new DyteAWSTranscribe({
  meeting,
  target: 'hi', // Optional if translate is false, Supported languages: https://docs.aws.amazon.com/translate/latest/dg/what-is-languages.html
  translate: true, // Control whether to translate the source language to target language or just transcribe
  source: 'en-US', // Supported languages: https://docs.aws.amazon.com/translate/latest/dg/what-is-languages.html
  preSignedUrlEndpoint: 'http://localhost:3001/aws-transcribe-presigned-url',
  translationEndpoint: 'http://localhost:3001/translate', // ${backend_url}/translate. backend_url is from step 2.4
});

awsTranscribe.on('transcription', async (data) => {
  // ... do something with transcription
});

awsTranscribe.transcribe();
```

Here you are setting up the DyteAWSTranscribe with the values that the current user would prefer and activating the recognition just afterward using awsTranscribe.transcribe(). Then we are listening to every new transcription using awsTranscribe.on(’transcription’, aJsCallbackFunction)

To see the support languages, please refer to https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html and https://docs.aws.amazon.com/translate/latest/dg/what-is-languages.html.

With this, now you would be able to receive the live transcriptions. Feel free to put them in UI as per your need.

If you need a sample of this guide, please refer to https://github.com/dyte-io/aws-transcribe/blob/main/client/demo/index.ts.
